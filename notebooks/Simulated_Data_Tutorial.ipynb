{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to make sure the `ART` library is available in your kernel.\n",
    "\n",
    "Clone the corresponding git repository:\n",
    "\n",
    "\n",
    "`git clone https://github.com/JBEI/AutomatedRecommendationTool.git`  \n",
    "\n",
    "or pull the latest version. \n",
    "\n",
    "Information about licensing ART is available at https://github.com/JBEI/ART.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then add library to the path and do the necessary import:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../AutomatedRecommendationTool')        # Make sure this is the location for the ART library \n",
    "    \n",
    "from art.core import *                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define true response function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_function(x, dimension):\n",
    "\n",
    "    f = 0.\n",
    "    for i in range(dimension):\n",
    "        f += x[i] ** 4 - 16 * x[i] ** 2 + 5 * x[i]\n",
    "\n",
    "    f *= 1 / dimension\n",
    "    return -1.*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, dimension):\n",
    "\n",
    "    term1 = 0.\n",
    "    term2 = 0.\n",
    "    for i in range(dimension):\n",
    "        term1 += (x[i] - 5)**2\n",
    "        term2 += x[i]**2\n",
    "\n",
    "    return -1*(1/dimension * term1 + np.exp(-term2)) + 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_optimum_value = {1: 25.,\n",
    "                        2: 78.332}\n",
    "global_optimum = {1: 5.*np.ones(dim),\n",
    "                  2: -2.903534*np.ones(dim)}\n",
    "\n",
    "lb = {1: -5, 2: -5}\n",
    "ub = {1: 10, 2: 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_number = 1\n",
    "n_cycles = 2\n",
    "alphas = [None, 1.]\n",
    "        \n",
    "global_optimum_value = global_optimum_value[func_number]\n",
    "global_optimum = global_optimum[func_number]\n",
    "lb = lb[func_number]\n",
    "ub = ub[func_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional variables for plotting models\n",
    "n_points = 50\n",
    "x1 = np.linspace(lb,ub,n_points)\n",
    "x2 = np.linspace(lb,ub,n_points)\n",
    "X1, Y1 = np.meshgrid(x1, x2)\n",
    "\n",
    "# pred_mean = np.zeros((n_points,n_points))\n",
    "# pred_std = np.zeros((n_points,n_points))\n",
    "# n_draws = 5000 # for sampling posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file with bounds\n",
    "bounds_file = '../data/sim_data_bounds.csv'\n",
    "df = pd.DataFrame(columns=['Variable', 'Min', 'Max', 'Scaling'])\n",
    "df['Variable'] = ['x_' + str(i) for i in range(1, dim + 1)]\n",
    "df['Min'] = lb*np.ones(dim)\n",
    "df['Max'] = ub*np.ones(dim)\n",
    "df['Scaling'] = np.ones(dim)\n",
    "df = df.set_index('Variable')\n",
    "df.to_csv(path_or_buf=bounds_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot functions for D=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dim = 2\n",
    "# 1\n",
    "Z1 = f1(np.array([X1, Y1]),dim)\n",
    "f_max1 = f1([5,5],dim)\n",
    "min_z1 = -100\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4.5), dpi=300)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax.plot_surface(X1, Y1, Z1, rstride=10, cstride=1, cmap=cmap, alpha=0.5,edgecolor='None')\n",
    "ax.scatter(5, 5, min_z1, s=50, c='r',edgecolor='r')\n",
    "ax.set_zlim3d(min_z1, f_max1)\n",
    "cset = ax.contour(X1, Y1, Z1, zdir='z', offset=min_z1, cmap=cmap)\n",
    "cset = ax.contour(X1, Y1, Z1, zdir='x', offset=-5, cmap=cmap)\n",
    "cset = ax.contour(X1, Y1, Z1, zdir='y', offset=10, cmap=cmap)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('$F_E(x)$')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'F_1.png')\n",
    "\n",
    "# 2\n",
    "fig = plt.figure(figsize=(4, 4.5), dpi=300)\n",
    "x1 = np.linspace(-5,5,50)\n",
    "x2 = np.linspace(-5,5,50)\n",
    "X2, Y2 = np.meshgrid(x1, x2)\n",
    "Z2 = f2(np.array([X2, Y2]),dim)\n",
    "f_max2 = f2([-2.903534, -2.903534],dim)\n",
    "min_z2 = -250\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax.plot_surface(X2, Y2, Z2, rstride=10, cstride=1, cmap=cmap, alpha=0.5,edgecolor='None')\n",
    "ax.set_zlim3d(min_z2, f_max2)\n",
    "ax.scatter(-2.903534, -2.903534, min_z2, s=50, c='r',edgecolor='r')\n",
    "cset = ax.contour(X2, Y2, Z2, zdir='z', offset=min_z2, cmap=cmap)\n",
    "cset = ax.contour(X2, Y2, Z2, zdir='x', offset=-5, cmap=cmap)\n",
    "cset = ax.contour(X2, Y2, Z2, zdir='y', offset=5, cmap=cmap)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('$F_M(x)$')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'F_2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = f'../data/sim_data_training.csv'\n",
    "art_params = {}\n",
    "art_params['bounds_file'] = bounds_file\n",
    "art_params['input_var'] = ['x_' + str(i) for i in range(1, dim + 1)]\n",
    "art_params['response_var'] = ['y']\n",
    "art_params['objective'] = 'maximize'\n",
    "art_params['threshold'] = 0.2\n",
    "art_params['verbose'] = 1\n",
    "art_params['seed'] = 42\n",
    "art_params['recommend'] = False\n",
    "art_params['output_directory'] = f'../results/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save simulated cycle 1 data into EDD-style files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_edd_csv(X, y, file_name):\n",
    "    \"\"\"A function to write EDD type files from a given data frame.\n",
    "    \n",
    "    # Create EDD style data file_name.csv with columns: Line Name / Type / 0\n",
    "    \"\"\"\n",
    "    \n",
    "    n_points = X.shape[0]\n",
    "    dim = X.shape[1]\n",
    "    \n",
    "    cols =  ['x_' + str(i) for i in range(1, dim + 1)]\n",
    "    line_names = [str(i) for i in range(n_points)]\n",
    "    \n",
    "    df = pd.DataFrame(X, index=line_names, columns=cols) \n",
    "    df['y'] = y\n",
    "    df.index.name = 'Line Name'\n",
    "\n",
    "    edd_df = pd.melt(df.reset_index(), id_vars=['Line Name'], value_vars=list(df.columns))\n",
    "    edd_df.columns = ['Line Name','Type',0.0]\n",
    "    edd_df.set_index('Line Name').to_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb, ub = -5, 10\n",
    "x1 = lb + lhs(dim, samples=n_points, criterion='maximin')*(ub - lb)\n",
    "y1 = f1(x1.T, dim)\n",
    "file_name = '../data/simulated_data/' + str(dim) + 'dim_benchmark_f1.csv'\n",
    "save_edd_csv(x1, y1, file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training data set using ART, LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cycle in range(init_cycle - 1, n_cycles):\n",
    "\n",
    "    print(f'Run {run}\\nCycle {cycle + 1}\\nAlpha = {alphas[cycle]}')\n",
    "\n",
    "    if cycle == 0:\n",
    "        data_file = f'../data/simulated_data/{bad_initial_dir}{str(dim)}dim_benchmark_f{str(func_number)}.csv'\n",
    "    else:\n",
    "        data_file = f'{art_params[\"output_directory\"]}/Data_Cycle{str(cycle + 1)}.csv'\n",
    "\n",
    "    art_params['alpha'] = alphas[cycle]\n",
    "\n",
    "    df = utils.load_study(data_file=data_file)\n",
    "    art = RecommendationEngine(df, **art_params)\n",
    "\n",
    "    # Save recommendations for the next cycle\n",
    "    file_path = f'{art.outDir}/recommendations_Cycle{str(cycle + 1)}.csv'\n",
    "    art.recommendations.to_csv(path_or_buf=file_path, sep='\\t')\n",
    "\n",
    "    # Evaluate models\n",
    "    art.evaluate_models()\n",
    "    mae_score_train[cycle] = art.model_df[0]['MAE']['Ensemble Model']\n",
    "    X_test = art.recommendations.values[:, :-1]\n",
    "    y_test = func(X_test.T, dim).reshape(-1, art.num_response_var)\n",
    "    art.evaluate_models(X_test, y_test)\n",
    "    mae_score_test[cycle] = art.model_df[0]['MAE']['Ensemble Model']\n",
    "\n",
    "    # error[run, cycle] = np.abs(art.recommendations.values[0, -1] - global_optimum_value)\n",
    "    best_prediction[cycle] = np.max(art.recommendations.values[:, -1])\n",
    "    std[cycle] = art.post_pred_stats(art.recommendations.values[0, :-1])[1][0][0]\n",
    "    cumulative_success_prob = art.calculate_success_prob(current_best=art.find_current_best())\n",
    "    prob_success[:, cycle] = cumulative_success_prob[0]\n",
    "\n",
    "    # Save data for the next cycle\n",
    "    X = np.concatenate((art.X, X_test))\n",
    "    y = np.concatenate((art.y, y_test))\n",
    "    file_name = f'{art.outDir}/Data_Cycle{str(cycle + 2)}.csv'\n",
    "    utils.save_edd_csv(X, y, art.input_var, file_name)\n",
    "\n",
    "    # For the first run, plot all models for each cycle\n",
    "    if run == 1:\n",
    "        plot.all_models_benchmark(art, func, dim, X1, Y1, lb, ub, global_optimum,\n",
    "                                  num_models=8, cycle=cycle, alpha=alphas[cycle])\n",
    "\n",
    "    # For each run, plot all models for the first cycle\n",
    "    if cycle == 0:\n",
    "        plot.all_models_benchmark(art, func, dim, X1, Y1, lb, ub, global_optimum,\n",
    "                                  num_models=8, cycle=cycle + 1, alpha=alphas[cycle])\n",
    "\n",
    "    # For each run and cycle save the metrics\n",
    "    for name, value in results.items():\n",
    "        file_name = f'{art.outDir}/{name}.csv'\n",
    "        np.savetxt(file_name, value, fmt='%4.4f', delimiter=',', newline='\\n')\n",
    "    \n",
    "# For each run save the metrics\n",
    "for name, value in results.items():\n",
    "    file_name = f'{art.outDir}/{name}.csv'\n",
    "    np.savetxt(file_name, value, fmt='%4.4f', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ART_v3.6",
   "language": "python",
   "name": "art_v3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
